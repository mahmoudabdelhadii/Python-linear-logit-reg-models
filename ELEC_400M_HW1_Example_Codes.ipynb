{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "qfeBhtmYn1lM"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "np.random.seed(0)\n",
        "random.seed(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lvKPmnK1d4F"
      },
      "source": [
        "# Q1 (e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "t2Zj5k9X2xec"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "# Implementation of matplotlib function\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "sWXQ5cEc1Z7v"
      },
      "outputs": [],
      "source": [
        "#Please modify the code and load X and y in training set\n",
        "\n",
        "X = np.array([\n",
        "     [0.3, 1.0],\n",
        "     [0.4, 2.0],\n",
        "     [0.5, 3.0]\n",
        "])\n",
        "y = np.array([\n",
        "    3.6,\n",
        "    6.8,\n",
        "    10.0\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "XesGqn7z3DwR"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'function' object has no attribute 'coef_'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Please use LinearRegression function in sklearn to fit the training set and report the fitted coefficient \u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mWrite you linear regression code here\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTheta: \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoef_\u001b[49m)\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'coef_'"
          ]
        }
      ],
      "source": [
        "# Please use LinearRegression function in sklearn to fit the training set and report the fitted coefficient \n",
        "'''\n",
        "Write you linear regression code here\n",
        "'''\n",
        "print(\"Theta: \", clf.coef_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDr11b_l4M6q"
      },
      "source": [
        "# Q2 (b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N-SmRgeL4aK3"
      },
      "outputs": [],
      "source": [
        "def calculate_loss(X, y, theta):\n",
        "    \"\"\"\n",
        "    Calculate the cross-entropy loss function given X, y, and theta\n",
        "    \"\"\"\n",
        "    f_x = X.dot(theta)\n",
        "    y_probs = 1 / (1 + np.exp(-f_x))\n",
        "    \n",
        "    '''\n",
        "    Please implement loss calculation here\n",
        "    \n",
        "    loss =\n",
        "\n",
        "    '''\n",
        "\n",
        "    return loss\n",
        "\n",
        "\n",
        "def calculate_grad(X, y, theta):\n",
        "    \"\"\"\n",
        "    Calculate the gradient of the cross-entropy loss w.r.t. theta\n",
        "    \"\"\"\n",
        "    f_x = X.dot(theta)\n",
        "    y_probs = 1 / (1 + np.exp(-f_x))\n",
        "\n",
        "    '''\n",
        "    Please implement loss calculation here\n",
        "    \n",
        "    theta_grad =\n",
        "\n",
        "    '''\n",
        "    return theta_grad\n",
        "\n",
        "\n",
        "def has_converged(loss, new_loss):\n",
        "    \"\"\"\n",
        "    Check if the model has converged and loss remains stable.\n",
        "    \"\"\"\n",
        "    return abs(loss - new_loss) < 0.000001\n",
        "    \n",
        "\n",
        "def calculate_new_theta(theta, theta_grad, alpha):\n",
        "    \"\"\"\n",
        "    Calculate the updated theta based on theta, gradient of theta, and step size\n",
        "    \"\"\"\n",
        "    return theta - alpha * theta_grad\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_RJQwhEk6Vps"
      },
      "outputs": [],
      "source": [
        "# Please load load X and y in training set\n",
        "\n",
        "'''\n",
        "Write your code here to initialize Data. \n",
        "X = \n",
        "y =\n",
        "'''\n",
        "\n",
        "# Initialize parameter and hyperparameters\n",
        "loss = float('inf')\n",
        "new_loss = float('inf')\n",
        "new_theta = np.array([float('inf'), float('inf'), float('inf')])\n",
        "\n",
        "'''\n",
        "initlizae theta and alpha\n",
        "theta = \n",
        "alpha = \n",
        "'''\n",
        "\n",
        "iters = 0\n",
        "\n",
        "# Perform Logistic Regression\n",
        "while not has_converged(loss, new_loss):\n",
        "    loss = new_loss\n",
        "    theta_grad = calculate_grad(X, y, theta)\n",
        "    new_theta = calculate_new_theta(theta, theta_grad, alpha)\n",
        "    new_loss = calculate_loss(X, y, new_theta)\n",
        "\n",
        "    theta = new_theta\n",
        "    iters += 1\n",
        "    # Uncomment the following line to print the loss at each step (for debugging purpose)\n",
        "    # print(f\"New Theta: {new_theta}, New Loss: {new_loss}, Iteration {iters}\")\n",
        "\n",
        "print(f\"Final Theta: {theta}, Loss: {calculate_loss(X, y, theta)}, Total Iterations: {iters}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDshGOqGTpWJ"
      },
      "source": [
        "# Q2 (c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eyMfZkHI6WJq"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MCS6-fQ5TvhW"
      },
      "outputs": [],
      "source": [
        "# Please load load X and y in training set\n",
        "\n",
        "'''\n",
        "Write your code here to initialize Data. \n",
        "X = \n",
        "y =\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E3gyH18kUFDT"
      },
      "outputs": [],
      "source": [
        "# Single Iteration\n",
        "\n",
        "'''\n",
        "Implement logitic regression using function LogisticRegression in sklearn and print the optimized coefficient after one iteration. \n",
        "\n",
        "Hint 1: By setting single iteration, please let max_iter = 1.\n",
        "\n",
        "Hint 2: To initialize the cofficient theta, please activate warm start and use clf.coef_ = theta to apply your initialization.\n",
        "\n",
        "Hint 3: Don't forget to change the default penalty and solver\n",
        "\n",
        "'''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lO12gUJmthxn"
      },
      "outputs": [],
      "source": [
        "# Final Solution\n",
        "\n",
        "'''\n",
        "Implement logitic regression using function LogisticRegression in sklearn and print the optimized coefficient after convergence. \n",
        "\n",
        "Hint 1: Setting a large max_iter to ensure convergence.\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5-IEWIB1toVQ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Copy of ELEC 400M HW1 Example Codes.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
