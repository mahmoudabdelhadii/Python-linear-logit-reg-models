{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of ELEC 400M HW1 Example Codes.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "np.random.seed(0)\n",
        "random.seed(0)"
      ],
      "metadata": {
        "id": "qfeBhtmYn1lM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q1 (e)"
      ],
      "metadata": {
        "id": "0lvKPmnK1d4F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression"
      ],
      "metadata": {
        "id": "t2Zj5k9X2xec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sWXQ5cEc1Z7v"
      },
      "outputs": [],
      "source": [
        "#Please modify the code and load X and y in training set\n",
        "\n",
        "X = np.array([\n",
        "     [0.3, 1.0],\n",
        "     [0.4, 2.0],\n",
        "     [0.5, 3.0]\n",
        "])\n",
        "y = np.array([\n",
        "    3.6,\n",
        "    6.8,\n",
        "    10.0\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Please use LinearRegression function in sklearn to fit the training set and report the fitted coefficient \n",
        "'''\n",
        "Write you linear regression code here\n",
        "'''\n",
        "print(\"Theta: \", clf.coef_)"
      ],
      "metadata": {
        "id": "XesGqn7z3DwR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q2 (b)"
      ],
      "metadata": {
        "id": "RDr11b_l4M6q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_loss(X, y, theta):\n",
        "    \"\"\"\n",
        "    Calculate the cross-entropy loss function given X, y, and theta\n",
        "    \"\"\"\n",
        "    f_x = X.dot(theta)\n",
        "    y_probs = 1 / (1 + np.exp(-f_x))\n",
        "    \n",
        "    '''\n",
        "    Please implement loss calculation here\n",
        "    \n",
        "    loss =\n",
        "\n",
        "    '''\n",
        "\n",
        "    return loss\n",
        "\n",
        "\n",
        "def calculate_grad(X, y, theta):\n",
        "    \"\"\"\n",
        "    Calculate the gradient of the cross-entropy loss w.r.t. theta\n",
        "    \"\"\"\n",
        "    f_x = X.dot(theta)\n",
        "    y_probs = 1 / (1 + np.exp(-f_x))\n",
        "\n",
        "    '''\n",
        "    Please implement loss calculation here\n",
        "    \n",
        "    theta_grad =\n",
        "\n",
        "    '''\n",
        "    return theta_grad\n",
        "\n",
        "\n",
        "def has_converged(loss, new_loss):\n",
        "    \"\"\"\n",
        "    Check if the model has converged and loss remains stable.\n",
        "    \"\"\"\n",
        "    return abs(loss - new_loss) < 0.000001\n",
        "    \n",
        "\n",
        "def calculate_new_theta(theta, theta_grad, alpha):\n",
        "    \"\"\"\n",
        "    Calculate the updated theta based on theta, gradient of theta, and step size\n",
        "    \"\"\"\n",
        "    return theta - alpha * theta_grad\n"
      ],
      "metadata": {
        "id": "N-SmRgeL4aK3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Please load load X and y in training set\n",
        "\n",
        "'''\n",
        "Write your code here to initialize Data. \n",
        "X = \n",
        "y =\n",
        "'''\n",
        "\n",
        "# Initialize parameter and hyperparameters\n",
        "loss = float('inf')\n",
        "new_loss = float('inf')\n",
        "new_theta = np.array([float('inf'), float('inf'), float('inf')])\n",
        "\n",
        "'''\n",
        "initlizae theta and alpha\n",
        "theta = \n",
        "alpha = \n",
        "'''\n",
        "\n",
        "iters = 0\n",
        "\n",
        "# Perform Logistic Regression\n",
        "while not has_converged(loss, new_loss):\n",
        "    loss = new_loss\n",
        "    theta_grad = calculate_grad(X, y, theta)\n",
        "    new_theta = calculate_new_theta(theta, theta_grad, alpha)\n",
        "    new_loss = calculate_loss(X, y, new_theta)\n",
        "\n",
        "    theta = new_theta\n",
        "    iters += 1\n",
        "    # Uncomment the following line to print the loss at each step (for debugging purpose)\n",
        "    # print(f\"New Theta: {new_theta}, New Loss: {new_loss}, Iteration {iters}\")\n",
        "\n",
        "print(f\"Final Theta: {theta}, Loss: {calculate_loss(X, y, theta)}, Total Iterations: {iters}\")"
      ],
      "metadata": {
        "id": "_RJQwhEk6Vps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q2 (c)"
      ],
      "metadata": {
        "id": "dDshGOqGTpWJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression"
      ],
      "metadata": {
        "id": "eyMfZkHI6WJq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Please load load X and y in training set\n",
        "\n",
        "'''\n",
        "Write your code here to initialize Data. \n",
        "X = \n",
        "y =\n",
        "'''"
      ],
      "metadata": {
        "id": "MCS6-fQ5TvhW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Single Iteration\n",
        "\n",
        "'''\n",
        "Implement logitic regression using function LogisticRegression in sklearn and print the optimized coefficient after one iteration. \n",
        "\n",
        "Hint 1: By setting single iteration, please let max_iter = 1.\n",
        "\n",
        "Hint 2: To initialize the cofficient theta, please activate warm start and use clf.coef_ = theta to apply your initialization.\n",
        "\n",
        "Hint 3: Don't forget to change the default penalty and solver\n",
        "\n",
        "'''\n"
      ],
      "metadata": {
        "id": "E3gyH18kUFDT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Final Solution\n",
        "\n",
        "'''\n",
        "Implement logitic regression using function LogisticRegression in sklearn and print the optimized coefficient after convergence. \n",
        "\n",
        "Hint 1: Setting a large max_iter to ensure convergence.\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "lO12gUJmthxn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "5-IEWIB1toVQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}